# SmartBike - Raspberry Pi 5 Optimized Streamlit Version
# Author: Amir Mobasheraghdam (adapted/optimized for RPi5)
# Human-Friendly Version with Persian UI Enhancements
# Notes:
#  - CPU-friendly settings (lower resolution, frame skipping, smaller imgsz)
#  - Requires: ultralytics, opencv-python, pyttsx3, streamlit, numpy
#  - Optional: streamlit-geolocation
# Run:
#   streamlit run smartbike_pi5_streamlit.py --server.address 0.0.0.0 --server.port 8501

import json
import time
import threading
from collections import deque
from typing import List, Tuple, Dict
from datetime import datetime
import cv2
import numpy as np
import streamlit as st
import pyttsx3
from ultralytics import YOLO

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ØªØ±
st.set_page_config(
    page_title="ğŸš´â€â™‚ï¸ SmartBike - Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§ÛŒÙ…Ù†ÛŒ Ø¯ÙˆÚ†Ø±Ø®Ù‡",
    page_icon="ğŸš´â€â™‚ï¸",
    layout="wide"
)

# --- Optional geolocation (won't break if missing) ---
try:
    from streamlit_geolocation import geolocation
    HAS_GEO = True
except Exception:
    HAS_GEO = False

# ---------------------- TTS (thread-safe) ----------------------
class Speaker:
    def __init__(self, rate: int = 150, volume: float = 1.0, enabled: bool = True, lang: str = "en"):
        self.enabled = enabled
        self.lang = lang
        self.engine = None
        self.lock = threading.Lock()
        if self.enabled:
            try:
                self.engine = pyttsx3.init()
                self.engine.setProperty("rate", rate)
                self.engine.setProperty("volume", volume)
                # Try to set language if available
                voices = self.engine.getProperty('voices')
                if lang == "fa" and len(voices) > 1:
                    try:
                        self.engine.setProperty('voice', voices[1].id)  # Try different voice
                    except:
                        pass
            except Exception:
                self.engine = None
                self.enabled = False

    def say_async(self, text: str):
        if not self.enabled or not self.engine or not text:
            return
        threading.Thread(target=self._speak_blocking, args=(text,), daemon=True).start()

    def _speak_blocking(self, text: str):
        with self.lock:
            try:
                self.engine.say(text)
                self.engine.runAndWait()
            except Exception:
                pass

# ---------------------- Persian Translations ----------------------
PERSIAN_TRANSLATIONS = {
    "person": "Ø¹Ø§Ø¨Ø± Ù¾ÛŒØ§Ø¯Ù‡",
    "car": "Ø®ÙˆØ¯Ø±Ùˆ",
    "bicycle": "Ø¯ÙˆÚ†Ø±Ø®Ù‡",
    "motorcycle": "Ù…ÙˆØªÙˆØ±Ø³ÛŒÚ©Ù„Øª",
    "bus": "Ø§ØªÙˆØ¨ÙˆØ³",
    "truck": "Ú©Ø§Ù…ÛŒÙˆÙ†",
    "traffic light": "Ú†Ø±Ø§Øº Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ",
    "stop sign": "Ø¹Ù„Ø§Ù…Øª ØªÙˆÙ‚Ù",
    "Left": "Ø³Ù…Øª Ú†Ù¾",
    "Right": "Ø³Ù…Øª Ø±Ø§Ø³Øª",
    "Center": "Ù…Ø³ØªÙ‚ÛŒÙ…",
    "FAST": "Ø³Ø±ÛŒØ¹",
    "Warning": "Ù‡Ø´Ø¯Ø§Ø±",
    "Danger": "Ø®Ø·Ø±",
    "Safe": "Ø§ÛŒÙ…Ù†"
}

def translate_to_persian(text: str) -> str:
    """Translate common terms to Persian for better UX"""
    return PERSIAN_TRANSLATIONS.get(text, text)

# ---------------------- App State ----------------------
if "hazards" not in st.session_state:
    st.session_state.hazards = []  # list of dicts: {"lat": float, "lng": float, "label": str, "ts": float}

if "object_histories" not in st.session_state:
    st.session_state.object_histories: Dict[str, deque] = {}

if "last_danger_spoken" not in st.session_state:
    st.session_state.last_danger_spoken = 0.0

if "run_flag" not in st.session_state:
    st.session_state.run_flag = False

if "performance_stats" not in st.session_state:
    st.session_state.performance_stats = {
        "fps": 0,
        "detection_time": 0,
        "objects_detected": 0,
        "warnings_issued": 0
    }

# ---------------------- UI Header ----------------------
st.markdown("""
<div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-bottom: 20px;">
    <h1 style="color: white; margin: 0;">ğŸš´â€â™‚ï¸ SmartBike - Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§ÛŒÙ…Ù†ÛŒ Ø¯ÙˆÚ†Ø±Ø®Ù‡</h1>
    <p style="color: rgba(255,255,255,0.9); margin: 5px 0 0 0;">
    Ù†Ø³Ø®Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Raspberry Pi 5 | ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡: <strong>Ø§Ù…ÛŒØ± Ù…Ø¨Ø´Ø±Ø§Øºâ€ŒØ¯Ù…</strong>
    </p>
    <p style="color: rgba(255,255,255,0.7); font-size: 14px; margin: 5px 0 0 0;">
    YOLOv8 + Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ + Ù‡Ø´Ø¯Ø§Ø±â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ + Ù†Ù‚Ø´Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ
    </p>
</div>
""", unsafe_allow_html=True)

# ---------------------- Sidebar Controls (Persian UI) ----------------------
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ RPi5)")

# Section 1: API Keys
st.sidebar.subheader("ğŸ”‘ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API")
api_key = st.sidebar.text_input(
    "Ú©Ù„ÛŒØ¯ Google Maps API",
    type="password",
    help="Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ØŒ Ú©Ù„ÛŒØ¯ Google Maps JavaScript API Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯"
)

# Section 2: Location
st.sidebar.subheader("ğŸ“ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ú©Ø§Ù†ÛŒ")
if HAS_GEO:
    loc_btn = st.sidebar.button("ğŸ“ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ú©Ø§Ù†ÛŒ Ù…Ù†", use_container_width=True)
else:
    st.sidebar.caption("Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù‚Ø§Ø¨Ù„ÛŒØª: pip install streamlit-geolocation")

default_lat, default_lng = 35.715298, 51.404343  # Tehran default

if HAS_GEO and "browser_loc" not in st.session_state:
    st.session_state.browser_loc = None
if HAS_GEO and "last_geo" not in st.session_state:
    st.session_state.last_geo = None

if HAS_GEO and loc_btn:
    st.session_state.last_geo = geolocation()
    if st.session_state.last_geo and "lat" in st.session_state.last_geo:
        st.session_state.browser_loc = (st.session_state.last_geo["lat"], st.session_state.last_geo["lon"])

lat = st.sidebar.number_input(
    "Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ",
    value=(st.session_state.browser_loc[0] if HAS_GEO and st.session_state.browser_loc else default_lat),
    format="%.6f",
    help="Latitude"
)

lng = st.sidebar.number_input(
    "Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ",
    value=(st.session_state.browser_loc[1] if HAS_GEO and st.session_state.browser_loc else default_lng),
    format="%.6f",
    help="Longitude"
)

# Section 3: Camera Settings
st.sidebar.subheader("ğŸ¥ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯ÙˆØ±Ø¨ÛŒÙ†")
cam_index = st.sidebar.number_input("Ø´Ù…Ø§Ø±Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ†", min_value=0, value=0, step=1, help="Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 0 Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø§ØµÙ„ÛŒ")

# Pi-friendly resolution
col_res1, col_res2 = st.sidebar.columns(2)
with col_res1:
    frame_w = st.selectbox("Ø¹Ø±Ø¶ ÙØ±ÛŒÙ…", [640, 800, 1280], index=0)
with col_res2:
    frame_h = st.selectbox("Ø§Ø±ØªÙØ§Ø¹ ÙØ±ÛŒÙ…", [360, 480, 720], index=0)

frame_skip = st.sidebar.slider("Ù¾Ø±Ø´ ÙØ±ÛŒÙ… (Ø§Ø¬Ø±Ø§ÛŒ YOLO Ø¯Ø± Ù‡Ø± N ÙØ±ÛŒÙ…)", 1, 5, 2, 1,
                               help="Ú©Ø§Ù‡Ø´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ø¹Ø¶ÛŒ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§")
imgsz = st.sidebar.selectbox("Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± YOLO (Ú©ÙˆÚ†Ú©ØªØ± = Ø³Ø±ÛŒØ¹â€ŒØªØ±)", [320, 416, 512, 640], index=1)

# Section 4: Detection Parameters
st.sidebar.subheader("ğŸ¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ")
conf_thresh = st.sidebar.slider("Ø­Ø¯Ø§Ù‚Ù„ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† ØªØ´Ø®ÛŒØµ", 0.1, 0.9, 0.45, 0.05,
                               help="Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…Ø¯Ù„ Ø¨Ù‡ ØªØ´Ø®ÛŒØµ Ø´ÛŒØ¡")
speed_thresh = st.sidebar.slider("Ø­Ø¯Ø§Ù‚Ù„ Ø³Ø±Ø¹Øª Ù‡Ø´Ø¯Ø§Ø± (Ù¾ÛŒÚ©Ø³Ù„/Ø«Ø§Ù†ÛŒÙ‡)", 20, 400, 120, 5,
                               help="Ø³Ø±Ø¹Øª Ø­Ø±Ú©Øª Ø´ÛŒØ¡ Ø¨Ø±Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø±")
danger_distance_m = st.sidebar.slider("ÙØ§ØµÙ„Ù‡ Ø®Ø·Ø±Ù†Ø§Ú© (Ù…ØªØ±)", 0.3, 5.0, 1.2, 0.1,
                                     help="ÙØ§ØµÙ„Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ø´ÛŒØ¡ Ø®Ø·Ø±Ù†Ø§Ú© Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯")

# Section 5: Audio Settings
st.sidebar.subheader("ğŸ—£ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙˆØªÛŒ")
tts_enabled = st.sidebar.checkbox("ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ ØµÙˆØªÛŒ", value=True)
tts_rate = st.sidebar.slider("Ø³Ø±Ø¹Øª Ú¯ÙØªØ§Ø±", 100, 220, 150, 5)
tts_lang = st.sidebar.selectbox("Ø²Ø¨Ø§Ù† Ú¯ÙØªØ§Ø±", ["Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ", "ÙØ§Ø±Ø³ÛŒ"], index=0)

# Section 6: Map Settings
st.sidebar.subheader("ğŸ—ºï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù‚Ø´Ù‡")
map_zoom = st.sidebar.slider("Ø¨Ø²Ø±Ú¯Ù†Ù…Ø§ÛŒÛŒ Ù†Ù‚Ø´Ù‡", 8, 20, 15)
show_map = st.sidebar.checkbox("Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ú¯ÙˆÚ¯Ù„", value=True)
auto_drop_hazard = st.sidebar.checkbox("Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ù‚Ø§Ø· Ø®Ø·Ø±", value=True,
                                      help="Ø«Ø¨Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù…ÙˆÙ‚Ø¹ÛŒØª Ù‡Ù†Ú¯Ø§Ù… Ø¯Ø±ÛŒØ§ÙØª Ù‡Ø´Ø¯Ø§Ø±")

max_hazards = st.sidebar.slider("Ø­Ø¯Ø§Ú©Ø«Ø± Ù†Ù‚Ø§Ø· Ø®Ø·Ø± Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡", 20, 300, 120, 10,
                               help="Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø³Ø±Ø¹Øª Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ")

# Section 7: Developer Info
st.sidebar.divider()
st.sidebar.markdown("""
<div style="background: #f0f2f6; padding: 15px; border-radius: 10px; border-right: 5px solid #4CAF50;">
    <p style="margin: 0; font-size: 14px;"><strong>ğŸ› ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡</strong></p>
    <p style="margin: 5px 0 0 0; font-size: 12px; color: #555;">
    ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡: <strong>Ø§Ù…ÛŒØ± Ù…Ø¨Ø´Ø±Ø§Øºâ€ŒØ¯Ù…</strong><br>
    Ù†Ø³Ø®Ù‡: Û².Û° (RPi5 Ø¨Ù‡ÛŒÙ†Ù‡)<br>
    Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: Û±Û´Û°Û³
    </p>
</div>
""", unsafe_allow_html=True)

if st.sidebar.button("ğŸ§¹ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ Ù†Ù‚Ø§Ø· Ø®Ø·Ø±", use_container_width=True):
    st.session_state.hazards = []
    st.success("âœ… Ù‡Ù…Ù‡ Ù†Ù‚Ø§Ø· Ø®Ø·Ø± Ù¾Ø§Ú© Ø´Ø¯Ù†Ø¯")

# ---------------------- Main Layout ----------------------
col1, col2 = st.columns([3, 2])

with col1:
    st.markdown("### ğŸ“· Ù†Ù…Ø§ÛŒØ´ Ø²Ù†Ø¯Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ†")
    st.caption(f"Ø±Ø²ÙˆÙ„ÙˆØ´Ù†: {frame_w}Ã—{frame_h} | ÙØ±ÛŒÙ…â€ŒØ§Ø³Ú©ÛŒÙ¾: {frame_skip} | Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø¯Ù„: {imgsz}")

with col2:
    st.markdown("### ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ ØªØ¹Ø§Ù…Ù„ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§")
    # Performance metrics
    metric_cols = st.columns(4)
    with metric_cols[0]:
        st.metric("FPS", f"{st.session_state.performance_stats['fps']:.1f}")
    with metric_cols[1]:
        st.metric("ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§", st.session_state.performance_stats['objects_detected'])
    with metric_cols[2]:
        st.metric("Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§", st.session_state.performance_stats['warnings_issued'])
    with metric_cols[3]:
        st.metric("Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´", f"{st.session_state.performance_stats['detection_time']:.1f}ms")

# ---------------------- Google Map Embed ----------------------
from streamlit.components.v1 import html as components_html

MAP_HTML_TMPL = """<!DOCTYPE html>
<html>
  <head>
    <meta name=viewport content="initial-scale=1, width=device-width" />
    <style>
      html, body, #map { height: 100%; margin: 0; padding: 0; }
      .label {
        background: rgba(0,0,0,0.75);
        color: #fff; padding: 5px 10px; border-radius: 6px; font-size: 12px;
        font-family: 'Tahoma', sans-serif;
      }
      .hazard-dot {
        background: #ff4444;
        width: 12px; height: 12px;
        border-radius: 50%;
        border: 2px solid white;
        box-shadow: 0 0 5px rgba(0,0,0,0.5);
      }
    </style>
    <script src="https://maps.googleapis.com/maps/api/js?key={API_KEY}&language=fa&region=IR"></script>
    <script>
      function init() {{
        const center = {{ lat: {CENTER_LAT}, lng: {CENTER_LNG} }};
        const map = new google.maps.Map(document.getElementById('map'), {{
          center: center,
          zoom: {ZOOM},
          mapTypeId: 'roadmap',
          streetViewControl: false,
          mapTypeControl: true,
          fullscreenControl: true,
          zoomControl: true
        }});

        // Current position marker (blue)
        const me = new google.maps.Marker({{
          position: center,
          map: map,
          title: 'Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´Ù…Ø§',
          icon: {{
            path: google.maps.SymbolPath.CIRCLE,
            scale: 8,
            fillColor: '#4285F4',
            fillOpacity: 1,
            strokeColor: '#FFFFFF',
            strokeWeight: 2
          }}
        }});

        const hazards = {HAZARDS_JSON};
        hazards.forEach(h => {{
          const m = new google.maps.Marker({{
            position: {{lat: h.lat, lng: h.lng}},
            map: map,
            title: h.label || 'Ù†Ù‚Ø·Ù‡ Ø®Ø·Ø±',
            icon: {{
              path: google.maps.SymbolPath.CIRCLE,
              scale: 6,
              fillColor: '#FF4444',
              fillOpacity: 0.8,
              strokeColor: '#FFFFFF',
              strokeWeight: 2
            }}
          }});
          const persianDate = new Date(h.ts*1000).toLocaleDateString('fa-IR');
          const timeStr = new Date(h.ts*1000).toLocaleTimeString('fa-IR');
          const infowindow = new google.maps.InfoWindow({{
            content: `<div class="label">
                      <strong>${h.label || 'Ù†Ù‚Ø·Ù‡ Ø®Ø·Ø±'}</strong><br/>
                      ØªØ§Ø±ÛŒØ®: ${persianDate}<br/>
                      Ø³Ø§Ø¹Øª: ${timeStr}
                      </div>`
          }});
          m.addListener('click', () => infowindow.open({{anchor: m, map}}));
        }});
      }}
      window.onload = init;
    </script>
  </head>
  <body>
    <div id="map"></div>
  </body>
</html>"""

def render_google_map(api_key: str, center: Tuple[float, float], zoom: int, hazards: List[dict]):
    if not api_key:
        st.info("ğŸ”‘ Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ Google Maps API Ø±Ø§ Ø¯Ø± Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯")
        return
    html = MAP_HTML_TMPL.format(
        API_KEY=api_key,
        CENTER_LAT=center[0],
        CENTER_LNG=center[1],
        ZOOM=int(zoom),
        HAZARDS_JSON=json.dumps(hazards),
    )
    components_html(html, height=420)

# ---------------------- Detection Setup ----------------------
IMPORTANT_CLASSES = ["person", "car", "bicycle", "motorcycle", "bus", "traffic light", "truck", "stop sign"]
REAL_WIDTHS = {
    "person": 0.5, "car": 1.8, "bicycle": 0.7, 
    "motorcycle": 0.8, "bus": 2.5, "truck": 2.5
}
FOCAL_LENGTH = 600  # approx
HISTORY_LENGTH = 8

@st.cache_resource(show_spinner=False)
def load_model():
    st.info("ğŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ù…Ø¯Ù„ YOLOv8... Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯")
    m = YOLO("yolov8n.pt")  # Using nano model for RPi5
    try:
        m.fuse()
        st.success("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø´Ø¯!")
    except Exception as e:
        st.warning(f"âš ï¸ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ú©Ø§Ù…Ù„ Ù†Ø¨ÙˆØ¯: {e}")
    return m

model = load_model()

# ---------------------- Control Buttons ----------------------
st.markdown("---")
control_col1, control_col2, control_col3, control_col4 = st.columns(4)

with control_col1:
    if st.button("â–¶ï¸ Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ…", use_container_width=True, type="primary"):
        st.session_state.run_flag = True
        st.session_state.performance_stats['warnings_issued'] = 0
        st.rerun()

with control_col2:
    if st.button("â¹ ØªÙˆÙ‚Ù Ø³ÛŒØ³ØªÙ…", use_container_width=True):
        st.session_state.run_flag = False
        st.rerun()

with control_col3:
    if st.button("ğŸ“¸ Ú¯Ø±ÙØªÙ† Ø¹Ú©Ø³", use_container_width=True):
        if 'last_frame' in st.session_state:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"smartbike_capture_{timestamp}.jpg"
            cv2.imwrite(filename, st.session_state.last_frame)
            st.success(f"âœ… Ø¹Ú©Ø³ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")

with control_col4:
    test_warning = st.button("ğŸ”Š ØªØ³Øª Ù‡Ø´Ø¯Ø§Ø± ØµÙˆØªÛŒ", use_container_width=True)
    if test_warning:
        test_speaker = Speaker(enabled=True)
        test_speaker.say_async("Ø³ÛŒØ³ØªÙ… SmartBike Ø¢Ù…Ø§Ø¯Ù‡ Ú©Ø§Ø± Ø§Ø³Øª. ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡: Ø§Ù…ÛŒØ± Ù…Ø¨Ø´Ø±Ø§Øºâ€ŒØ¯Ù…")

# Placeholders for dynamic content
FRAME_PLACEHOLDER = col1.empty()
LOG_PLACEHOLDER = col2.empty()
MAP_PLACEHOLDER = col2.empty()

speaker = Speaker(rate=tts_rate, enabled=tts_enabled, lang="fa" if tts_lang == "ÙØ§Ø±Ø³ÛŒ" else "en")

# ---------------------- Camera Open Function ----------------------
def open_camera(index: int, w: int, h: int):
    cap = cv2.VideoCapture(int(index), cv2.CAP_V4L2)
    if not cap.isOpened():
        # Try without V4L2 as fallback
        cap = cv2.VideoCapture(int(index))
    if not cap.isOpened():
        return None
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, int(w))
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, int(h))
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    cap.set(cv2.CAP_PROP_FPS, 15)  # Limit FPS for RPi5
    return cap

# ---------------------- Helper Functions ----------------------
def is_red_light(roi_bgr: np.ndarray) -> bool:
    """ØªØ´Ø®ÛŒØµ Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø² Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±"""
    if roi_bgr.size == 0:
        return False
    hsv = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2HSV)
    lower1 = np.array([0, 120, 120])
    upper1 = np.array([10, 255, 255])
    lower2 = np.array([160, 120, 120])
    upper2 = np.array([180, 255, 255])
    mask = cv2.inRange(hsv, lower1, upper1) | cv2.inRange(hsv, lower2, upper2)
    red_ratio = float(mask.mean()) / 255.0
    return red_ratio > 0.1

def get_warning_message(persian_name: str, position: str, distance: float, speed_warn: bool) -> str:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒØ§Ù… Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ"""
    position_fa = translate_to_persian(position)
    
    if distance < danger_distance_m:
        if speed_warn:
            return f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±! {persian_name} Ø³Ø±ÛŒØ¹ Ø§Ø² {position_fa} Ù†Ø²Ø¯ÛŒÚ© Ù…ÛŒâ€ŒØ´ÙˆØ¯! ÙØ§ØµÙ„Ù‡: {distance:.1f} Ù…ØªØ±"
        else:
            return f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±! {persian_name} Ø¯Ø± {position_fa} Ø®ÛŒÙ„ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø§Ø³Øª! ÙØ§ØµÙ„Ù‡: {distance:.1f} Ù…ØªØ±"
    elif speed_warn:
        return f"âš ï¸ ØªÙˆØ¬Ù‡! {persian_name} Ø³Ø±ÛŒØ¹ Ø§Ø² {position_fa} Ø¯Ø± Ø­Ø§Ù„ Ø­Ø±Ú©Øª Ø§Ø³Øª"
    
    return ""

# ---------------------- Main Processing Loop ----------------------
cap = None
last_map_render = 0.0
frame_i = 0
last_fps_time = time.time()
frame_count = 0

if st.session_state.run_flag:
    cap = open_camera(cam_index, frame_w, frame_h)
    if cap is None:
        st.error("âŒ Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª! Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:")
        st.error("1. Ø¯ÙˆØ±Ø¨ÛŒÙ† Ø¨Ù‡ Ø±Ø²Ø¨Ø±ÛŒ Ù¾Ø§ÛŒ Ù…ØªØµÙ„ Ø§Ø³Øª")
        st.error("2. Ø´Ù…Ø§Ø±Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ† ØµØ­ÛŒØ­ Ø§Ø³Øª")
        st.error("3. Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ (sudo usermod -a -G video $USER)")
        st.session_state.run_flag = False

while st.session_state.run_flag:
    start_time = time.time()
    ok, frame = cap.read()
    
    if not ok:
        st.warning("âš ï¸ Ø¯Ø±ÛŒØ§ÙØª ÙØ±ÛŒÙ… Ø§Ø² Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
        time.sleep(0.1)
        continue
    
    # Store last frame for capture functionality
    st.session_state.last_frame = frame.copy()
    
    frame_i += 1
    frame_count += 1
    h, w = frame.shape[:2]
    
    # Calculate FPS
    current_time = time.time()
    if current_time - last_fps_time >= 1.0:
        st.session_state.performance_stats['fps'] = frame_count
        frame_count = 0
        last_fps_time = current_time
    
    # Run YOLO only every N frames for performance
    do_infer = (frame_i % int(frame_skip) == 0)
    
    speech_chunks = []
    red_light_detected = False
    warning_detected = False
    
    if do_infer:
        infer_start = time.time()
        
        # YOLO inference with optimized settings for RPi5
        results = model.predict(
            frame, 
            conf=conf_thresh, 
            imgsz=int(imgsz), 
            verbose=False,
            half=False,  # Don't use half precision on CPU
            max_det=10,  # Limit detections
            agnostic_nms=True
        )[0]
        
        infer_time = (time.time() - infer_start) * 1000
        st.session_state.performance_stats['detection_time'] = infer_time
        
        detected_objects = 0
        
        for box in results.boxes:
            cls_id = int(box.cls[0])
            class_name = model.names.get(cls_id, str(cls_id))
            
            if class_name not in IMPORTANT_CLASSES:
                continue
            
            detected_objects += 1
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
            bw = max(1, x2 - x1)
            
            # Determine position (Left/Center/Right)
            if cx < w / 3:
                position = "Left"
            elif cx > 2 * w / 3:
                position = "Right"
            else:
                position = "Center"
            
            # Track object history for speed calculation
            hist_key = f"{class_name}_{position}"
            hist = st.session_state.object_histories.setdefault(
                hist_key, 
                deque(maxlen=HISTORY_LENGTH)
            )
            hist.append((time.time(), cx, cy))
            
            # Calculate speed if we have history
            speed_warn = False
            if len(hist) >= 2:
                t0, x0, y0 = hist[0]
                t1, x1n, y1n = hist[-1]
                dt = max(1e-3, t1 - t0)
                pix_dist = float(np.hypot(x1n - x0, y1n - y0))
                speed = pix_dist / dt
                if speed > speed_thresh:
                    speed_warn = True
            
            # Estimate distance (if we know real width)
            distance_m = None
            if class_name in REAL_WIDTHS:
                distance_m = round((REAL_WIDTHS[class_name] * FOCAL_LENGTH) / bw, 2)
            
            # Generate warning messages
            persian_name = translate_to_persian(class_name)
            warning_msg = ""
            
            if class_name == "traffic light":
                roi = frame[max(0, y1):max(0, y2), max(0, x1):max(0, x2)]
                if is_red_light(roi):
                    red_light_detected = True
                    warning_msg = "ğŸš¦ Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø² Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯! ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯."
                    cv2.putText(frame, "ğŸš¦ Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø²", (x1, y1-40), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            elif distance_m is not None:
                warning_msg = get_warning_message(persian_name, position, distance_m, speed_warn)
                if warning_msg:
                    warning_detected = True
            
            # Add to speech queue
            if warning_msg:
                speech_chunks.append(warning_msg)
                st.session_state.performance_stats['warnings_issued'] += 1
            
            # Draw on frame (with Persian labels)
            color = (0, 0, 255) if warning_msg else (0, 255, 0)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Create label with Persian text
            label_parts = [persian_name]
            if distance_m is not None:
                label_parts.append(f"{distance_m}m")
            if speed_warn:
                label_parts.append("Ø³Ø±ÛŒØ¹")
            
            label = " | ".join(label_parts)
            
            # Draw background for better text visibility
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(frame, (x1, y1-25), (x1+text_size[0]+10, y1), color, -1)
            cv2.putText(frame, label, (x1+5, y1-8), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw small direction indicator
            if position == "Left":
                cv2.putText(frame, "â†", (x1, y1-50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            elif position == "Right":
                cv2.putText(frame, "â†’", (x1, y1-50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        st.session_state.performance_stats['objects_detected'] = detected_objects
    
    # Add timestamp and stats to frame
    timestamp = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
    fps_text = f"FPS: {st.session_state.performance_stats['fps']}"
    cv2.putText(frame, timestamp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(frame, fps_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(frame, f"ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§: {st.session_state.performance_stats['objects_detected']}", 
               (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # Draw center guidelines
    cv2.line(frame, (w//3, 0), (w//3, h), (255, 255, 0), 1)
    cv2.line(frame, (2*w//3, 0), (2*w//3, h), (255, 255, 0), 1)
    cv2.putText(frame, "Ú†Ù¾", (w//6, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
    cv2.putText(frame, "ÙˆØ³Ø·", (w//2, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
    cv2.putText(frame, "Ø±Ø§Ø³Øª", (5*w//6, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
    
    # Speak warnings (debounced)
    now = time.time()
    if speech_chunks and (now - st.session_state.last_danger_spoken > 2.0):
        # Speak only the most important warning
        if red_light_detected:
            warning_to_speak = "Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø² Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯! ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯."
        else:
            warning_to_speak = speech_chunks[0]
        
        speaker.say_async(warning_to_speak)
        st.session_state.last_danger_spoken = now
    
    # Auto hazard marker (keep list bounded)
    if auto_drop_hazard and (red_light_detected or warning_detected):
        hazard_label = "Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø²" if red_light_detected else "Ø®Ø·Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ"
        st.session_state.hazards.append({
            "lat": float(lat),
            "lng": float(lng),
            "label": hazard_label,
            "ts": now,
        })
        # Keep only recent hazards
        if len(st.session_state.hazards) > int(max_hazards):
            st.session_state.hazards = st.session_state.hazards[-int(max_hazards):]
    
    # Display frame
    FRAME_PLACEHOLDER.image(
        cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), 
        caption=f"Ù†Ù…Ø§ÛŒØ´ Ø²Ù†Ø¯Ù‡ - ÙØ±ÛŒÙ… {frame_i}", 
        use_column_width=True
    )
    
    # Display warnings log
    if speech_chunks or red_light_detected:
        log_content = "### ğŸ”” Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±:\n"
        for msg in speech_chunks:
            log_content += f"â€¢ {msg}\n"
        if red_light_detected:
            log_content += "â€¢ ğŸš¦ Ú†Ø±Ø§Øº Ù‚Ø±Ù…Ø² Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯!\n"
        
        LOG_PLACEHOLDER.markdown(log_content)
    
    # Update map (rate-limited)
    if show_map and (now - last_map_render > 2.0):
        with MAP_PLACEHOLDER:
            render_google_map(api_key, (lat, lng), map_zoom, st.session_state.hazards)
        last_map_render = now
    
    # Small delay for UI responsiveness
    time.sleep(0.01)

# ---------------------- Cleanup ----------------------
if cap is not None:
    cap.release()
    cv2.destroyAllWindows()

# Final message when stopped
if not st.session_state.run_flag and 'cap' in locals():
    st.success("âœ… Ø³ÛŒØ³ØªÙ… Ù…ØªÙˆÙ‚Ù Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ù…Ø¬Ø¯Ø¯ Ø¯Ú©Ù…Ù‡ 'Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ…' Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")
    
    # Show summary
    st.markdown("### ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯")
    col_sum1, col_sum2, col_sum3 = st.columns(3)
    with col_sum1:
        st.metric("Ú©Ù„ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§", frame_i)
    with col_sum2:
        st.metric("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† FPS", f"{st.session_state.performance_stats['fps']:.1f}")
    with col_sum3:
        st.metric("Ù†Ù‚Ø§Ø· Ø®Ø·Ø± Ø«Ø¨Øª Ø´Ø¯Ù‡", len(st.session_state.hazards))
